{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorials from which we took some code (adapted):\n",
    "# - https://nextjournal.com/gkoehler/pytorch-mnist\n",
    "# - https://medium.com/@nutanbhogendrasharma/pytorch-convolutional-neural-network-with-mnist-dataset-4e8a4265e118\n",
    "# - for cross-validation: https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-pytorch.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants\n",
    "BATCH_SIZE_TRAIN = 32\n",
    "BATCH_SIZE_TEST = 1000 # I don't think this actually matters\n",
    "\n",
    "K_FOLDS = 2 #5\n",
    "\n",
    "NUMBER_OF_EPOCHS = 2\n",
    "LEARNING_RATE = 0.05\n",
    "MOMENTUM = 0\n",
    "\n",
    "USE_PNG_FORMAT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exercise2_config as config\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from torch.utils.data import TensorDataset, ConcatDataset, DataLoader\n",
    "import readers\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "seed = round(datetime.timestamp(datetime.now()))\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "print(f'Seed = {seed}')\n",
    "\n",
    "\n",
    "def BuildDataLoadersFromCsvFiles(permutated):\n",
    "  if(permutated):\n",
    "    train_images = pd.read_csv(\"../mnist/trainOutput.csv\", header=None)\n",
    "    test_images = pd.read_csv(\"../mnist/testOutput.csv\", header=None)\n",
    "  else:\n",
    "    train_images = pd.read_csv(config.TRAIN_DATA_FILE, header=None)\n",
    "    test_images = pd.read_csv(config.TEST_DATA_FILE, header=None)\n",
    "\n",
    "  train_data = np.array(train_images.iloc[:,1:])\n",
    "  train_labels = np.array(train_images.iloc[:,0])\n",
    "  test_data = np.array(test_images.iloc[:,1:])\n",
    "  test_labels = np.array(test_images.iloc[:,0])\n",
    "\n",
    "  train_data = np.reshape(train_data, (len(train_data), 1, 28, 28))\n",
    "  # Normalize the data\n",
    "  train_data = torch.from_numpy(train_data).float()/255\n",
    "  train_labels = torch.from_numpy(np.array(train_labels))\n",
    "  train_set = TensorDataset(train_data, train_labels)\n",
    "\n",
    "  test_data = np.reshape(test_data, (len(test_data), 1, 28, 28))\n",
    "  # Normalize the data\n",
    "  test_data = torch.from_numpy(test_data).float()/255\n",
    "  test_labels = torch.from_numpy(np.array(test_labels))\n",
    "  test_set = TensorDataset(test_data, test_labels)\n",
    "  \n",
    "  train_loader = DataLoader(train_set, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "  test_loader = DataLoader(test_set, batch_size=BATCH_SIZE_TEST, shuffle=True)\n",
    "  return train_loader, test_loader\n",
    "\n",
    "\n",
    "# We first import the data and convert them to a torch version\n",
    "def BuildDataLoaders(use_png_format=USE_PNG_FORMAT):\n",
    "  if use_png_format:\n",
    "    readers.ReadFromPngFiles()\n",
    "    return BuildDataLoadersFromCsvFiles(use_png_format)\n",
    "  return BuildDataLoadersFromCsvFiles(use_png_format)\n",
    "\n",
    "\n",
    "original_train_loader, original_test_loader = BuildDataLoaders()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import model_task2c\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "\n",
    "# Needed in order to detect if any values become nan\n",
    "# This was the case at some point, but it's not really useful anymore.\n",
    "torch.autograd.set_detect_anomaly(True) \n",
    "\n",
    "\n",
    "# Compute the accuracy of the model on the given data set \n",
    "# and returns the loss. \n",
    "def ComputeAccuracy(loader, data_label, model, loss_func='cross_entropy'):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    number_of_tests = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, (data, label) in enumerate(loader):\n",
    "            output = model(data)\n",
    "            \n",
    "            if loss_func == 'cross_entropy':\n",
    "                total_loss += F.cross_entropy(output, label, reduction='sum').item()\n",
    "            else:\n",
    "                total_loss += F.nll_loss(output, label, reduction='sum').item()\n",
    "\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(label.data.view_as(pred)).sum()\n",
    "            number_of_tests += len(data)\n",
    "\n",
    "    \n",
    "    average_loss = total_loss / number_of_tests\n",
    "    accuracy = 100. * correct / number_of_tests\n",
    "    print(f'Accuracy {data_label}: {correct}/{number_of_tests} ({accuracy:.2f}%)')\n",
    "    print(f'Average loss: {average_loss:.4f}\\n')\n",
    "\n",
    "    return accuracy, average_loss\n",
    "\n",
    "\n",
    "# Trains a model using the given train dataset and returns the following (in this order):\n",
    "# - model\n",
    "# - train_loss_per_epoch\n",
    "# - test_loss_per_epoch\n",
    "# - train_accuracy_per_epoch\n",
    "# - test_accuracy_per_epoch\n",
    "# - learning_rate_per_epoch\n",
    "def train(train_loader, test_loader, number_of_epochs, learning_rate, loss_func='cross_entropy'):\n",
    "    # Initialize classifier stuff\n",
    "    model = model_task2c.PR_CNN()   # initialization of the model\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=MOMENTUM)\n",
    "\n",
    "    train_loss_per_epoch = []\n",
    "    train_accuracy_per_epoch = []\n",
    "    test_loss_per_epoch = []\n",
    "    test_accuracy_per_epoch = []\n",
    "    learning_rate_per_epoch = []\n",
    "\n",
    "    #To optimize the learning rate with LambdaLR\n",
    "    #From https://www.kaggle.com/code/isbhargav/guide-to-pytorch-learning-rate-scheduling/notebook\n",
    "    # The learning rate will be 10% smaller from one epoch to another\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=(lambda factor: 0.9 ** factor))\n",
    "\n",
    "    for epoch in range(number_of_epochs):\n",
    "        print(f'Epoch {epoch + 1}')\n",
    "        current_learning_rate = round(optimizer.param_groups[0][\"lr\"],3)\n",
    "        print(f'Learning Rate: {current_learning_rate}')\n",
    "        learning_rate_per_epoch.append(current_learning_rate)\n",
    "\n",
    "        model.train()  # activation of the train mode\n",
    "\n",
    "        for _, (data, label) in enumerate(train_loader):\n",
    "            # Set gradients to 0. PyTorch accumulates the gradients \n",
    "            # https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            output = model(data)\n",
    "\n",
    "            if loss_func == 'cross_entropy':\n",
    "                loss = F.cross_entropy(output, label)\n",
    "            else:\n",
    "                loss = F.nll_loss(output, label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Compute the accuracy of the model at the end of each epoch\n",
    "        train_accuracy, train_loss = ComputeAccuracy(train_loader, 'train', model, loss_func)\n",
    "        train_loss_per_epoch.append(train_loss)\n",
    "        train_accuracy_per_epoch.append(train_accuracy)\n",
    "        \n",
    "        test_accuracy, test_loss = ComputeAccuracy(test_loader, 'test', model, loss_func)\n",
    "        test_loss_per_epoch.append(test_loss)\n",
    "        test_accuracy_per_epoch.append(test_accuracy)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    return model, train_loss_per_epoch, test_loss_per_epoch, train_accuracy_per_epoch, test_accuracy_per_epoch, learning_rate_per_epoch\n",
    "\n",
    "\n",
    "# Trains a model using the given train dataset and returns the following (in this order):\n",
    "# - model\n",
    "# - train_loss_per_epoch\n",
    "# - test_loss_per_epoch\n",
    "# - train_accuracy_per_epoch\n",
    "# - test_accuracy_per_epoch\n",
    "# - learning_rate_per_epoch\n",
    "def TrainWithoutCrossValidation(train_loader, test_loader):\n",
    "    return train(train_loader, test_loader, NUMBER_OF_EPOCHS, LEARNING_RATE)\n",
    "\n",
    "\n",
    "# Returns the average accuracy obtained on the validation set for each fold.\n",
    "def TrainWithCrossValidationAndFixedParams(train_loader, number_of_epochs, learning_rate):\n",
    "    kfold = KFold(n_splits=K_FOLDS, shuffle=True)\n",
    "    # Sum of accuracies obtained on the validation sets for each fold\n",
    "    sum_accuracy_validation_set = 0\n",
    "\n",
    "    for fold, (train_ids, validation_ids) in enumerate(kfold.split(train_loader.dataset)):\n",
    "        print(f'Fold {fold + 1}')\n",
    "\n",
    "        # Sample elements randomly from a given list, no replacement.\n",
    "        train_subsampler = SubsetRandomSampler(train_ids)\n",
    "        validation_subsampler = SubsetRandomSampler(validation_ids)\n",
    "        \n",
    "        fold_train_loader = DataLoader(train_loader.dataset, batch_size=BATCH_SIZE_TRAIN, sampler=train_subsampler)\n",
    "        fold_validation_loader = DataLoader(train_loader.dataset, batch_size=BATCH_SIZE_TEST, sampler=validation_subsampler)\n",
    "\n",
    "        _, _, _, _, fold_test_accuracy_per_epoch, _ = \\\n",
    "            train(fold_train_loader, fold_validation_loader, number_of_epochs, learning_rate)     \n",
    "        # Add final accuracy\n",
    "        sum_accuracy_validation_set += fold_test_accuracy_per_epoch[-1]\n",
    "        \n",
    "        print('--------------------------------------------------')   \n",
    "\n",
    "    return sum_accuracy_validation_set / K_FOLDS\n",
    "\n",
    "\n",
    "# Trains a model using the given train dataset and returns the following (in this order):\n",
    "# - model\n",
    "# - train_loss_per_epoch\n",
    "# - test_loss_per_epoch\n",
    "# - train_accuracy_per_epoch\n",
    "# - test_accuracy_per_epoch\n",
    "# - learning_rate_per_epoch\n",
    "def TrainWithCrossValidation(train_loader, test_loader):\n",
    "    best_accuracy = 0\n",
    "    number_of_epochs_for_best_accuracy = None\n",
    "    learning_rate_for_best_accuracy = None\n",
    "\n",
    "    \n",
    "    # Identify the best number of epochs and learning rate\n",
    "    for number_of_epochs in [2]: #[10, 15, 20]\n",
    "        for learning_rate in [0.01, 0.05, 0.1]:\n",
    "            print(f'NUMBER OF EPOCHS = {number_of_epochs}, LEARNING RATE = {learning_rate}')\n",
    "\n",
    "            average_accuracy_cross_validation = \\\n",
    "                TrainWithCrossValidationAndFixedParams(train_loader, number_of_epochs, learning_rate)\n",
    "            print(f'average_accuracy_cross_validation = {average_accuracy_cross_validation}')\n",
    "\n",
    "            if average_accuracy_cross_validation > best_accuracy:\n",
    "                best_accuracy = average_accuracy_cross_validation\n",
    "                number_of_epochs_for_best_accuracy = number_of_epochs\n",
    "                learning_rate_for_best_accuracy = learning_rate\n",
    "\n",
    "            print('==================================================')   \n",
    "\n",
    "    # Train a model on the best number of epochs and learning rate\n",
    "    print(f'BEST NUMBER OF EPOCHS = {number_of_epochs_for_best_accuracy}, BEST LEARNING RATE = {learning_rate_for_best_accuracy}')\n",
    "    return train(train_loader, test_loader, number_of_epochs_for_best_accuracy, learning_rate_for_best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "# Without cross validation \n",
    "# cnn_model, train_loss_per_epoch, test_loss_per_epoch, train_accuracy_per_epoch, test_accuracy_per_epoch, learning_rate_per_epoch = \\\n",
    "#   TrainWithoutCrossValidation(original_train_loader, original_test_loader)\n",
    "\n",
    "# With cross validation\n",
    "cnn_model, train_loss_per_epoch, test_loss_per_epoch, train_accuracy_per_epoch, test_accuracy_per_epoch, learning_rate_per_epoch = \\\n",
    "  TrainWithCrossValidation(original_train_loader, original_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# Saves a model to a file in the same directory as this script.\n",
    "def SaveModel(model):\n",
    "  filename = os.path.join(os.path.abspath(''), 'cnn_model.pt')\n",
    "  torch.save(model.state_dict(), filename)\n",
    "  pass\n",
    "\n",
    "\n",
    "# Loads a model from a file.\n",
    "def LoadModel(filename=os.path.join(os.path.abspath(''), 'cnn_model.pt')):\n",
    "  model = model_task2c.PR_CNN()\n",
    "  model.load_state_dict(torch.load(filename))\n",
    "  return model\n",
    "\n",
    "\n",
    "# SaveModel(cnn_model)\n",
    "# cnn_model = LoadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot showing the accuracy and loss on the training and the test set with respect to the training epochs, for the best configuration found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to install ipympl to make this work\n",
    "%matplotlib widget\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "epochs = [i for i in range(1, len(train_accuracy_per_epoch) + 1)]\n",
    "fig, axes = plt.subplots(3, 1, constrained_layout=True)\n",
    "fig.canvas.toolbar_visible = False\n",
    "fig.canvas.header_visible = False\n",
    "\n",
    "\n",
    "# Show accuracy\n",
    "axes[0].plot(epochs, train_accuracy_per_epoch,'-o')\n",
    "axes[0].plot(epochs, test_accuracy_per_epoch, '-o')\n",
    "axes[0].set_xticks(epochs)\n",
    "axes[0].legend(['Train', 'Test'])\n",
    "axes[0].set_title('Accuracy')\n",
    "\n",
    "\n",
    "# Show loss\n",
    "axes[1].plot(epochs, train_loss_per_epoch,'-o')\n",
    "axes[1].plot(epochs, test_loss_per_epoch, '-o')\n",
    "axes[1].set_xticks(epochs)\n",
    "axes[1].legend(['Train', 'Test'])\n",
    "axes[1].set_title('Loss')\n",
    "\n",
    "\n",
    "# Show learning rate per epoch\n",
    "axes[2].plot(epochs, learning_rate_per_epoch,'-o')\n",
    "axes[2].set_xticks(epochs)\n",
    "axes[2].set_title('Learning Rate')\n",
    "for epoch in epochs:\n",
    "  # Epochs start at 1, indexes at 0\n",
    "  axes[2].text(epoch, learning_rate_per_epoch[epoch - 1], learning_rate_per_epoch[epoch - 1])\n",
    "  pass\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Code taken from here: https://timodenk.com/blog/exporting-matplotlib-plots-to-latex/\n",
    "\"\"\"\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "plot_filename = os.path.join(os.path.abspath(''), 'cnn_model_plot.pgf')\n",
    "plt.savefig(plot_filename)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnn_model)\n",
    "print(f'Batch size = {BATCH_SIZE_TRAIN}')\n",
    "print(f'Number of epochs = {len(train_accuracy_per_epoch)}')\n",
    "print(f'Learning rate at start = {learning_rate_per_epoch[0]}')\n",
    "\n",
    "# Compute the accuracy of the model on the test dataset\n",
    "ComputeAccuracy(original_test_loader, 'test', cnn_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
