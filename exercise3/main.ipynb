{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import exercise3_config as config\n",
    "\n",
    "\n",
    "# Output:\n",
    "#  - list of size n containing image numbers\n",
    "#  - list of size n containing paths to original jpg images\n",
    "#  - list of size n containing paths to svg masks\n",
    "def ExtractImagePaths(text_file_path):\n",
    "  images_numbers = []\n",
    "  jpg_paths = []\n",
    "  svg_paths = []\n",
    "\n",
    "  with open(text_file_path) as file:\n",
    "    for image_number in file.readlines():\n",
    "      images_numbers.append(str(int(image_number)))\n",
    "      jpg_image_path = os.path.join(config.DATA_ROOT_DIR, 'images/' + str(int(image_number)) + '.jpg')\n",
    "      jpg_paths.append(jpg_image_path)\n",
    "      svg_image_path = os.path.join(config.DATA_ROOT_DIR, 'ground-truth/locations/' + str(int(image_number)) + '.svg')\n",
    "      svg_paths.append(svg_image_path)\n",
    "\n",
    "  return images_numbers, jpg_paths, svg_paths\n",
    "\n",
    "\n",
    "# Extract paths for train and test files\n",
    "train_images_numbers, train_jpg_paths, train_svg_paths = \\\n",
    "  ExtractImagePaths(os.path.join(config.DATA_ROOT_DIR, 'task/train.txt'))\n",
    "test_images_numbers, test_jpg_paths, test_svg_paths = \\\n",
    "  ExtractImagePaths(os.path.join(config.DATA_ROOT_DIR, 'task/valid.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from image_preprocessing import CropAllWordImages\n",
    "\n",
    "\n",
    "# TODO: remove this, apply OTSU. This method is here now just for the sake of testing the whole pipeline.\n",
    "# Applies KMeans clustering with the given k on the image at the given path \n",
    "# and returns the output as a a PIL.Image.\n",
    "def ApplyKMeansClusteringToImageFile(jpg_image_filename, k=2):\n",
    "  original_image = cv.imread(jpg_image_filename)\n",
    "  pixels = original_image.reshape((-1,3))\n",
    "  pixels = np.float32(pixels)\n",
    "\n",
    "  # Define criteria, number of clusters and apply KMeans.\n",
    "  criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "  _, label, center = cv.kmeans(pixels, k, None, criteria, 10, cv.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "  # Convert back into uint8.\n",
    "  center = np.uint8(center)\n",
    "  final_image_pixels = center[label.flatten()]\n",
    "  final_image_pixels = final_image_pixels.reshape((original_image.shape))\n",
    "\n",
    "  return Image.fromarray(final_image_pixels)\n",
    "\n",
    "\n",
    "def ExtractWordImagesFromOriginalImage(original_image_path, mask_path):\n",
    "  image_after_binarization = ApplyKMeansClusteringToImageFile(original_image_path)\n",
    "  return CropAllWordImages(image_after_binarization, mask_path)\n",
    "\n",
    "\n",
    "# Extract all words needed for train and test\n",
    "train_words_per_image = {}\n",
    "for index in range(len(train_images_numbers)):\n",
    "  train_words_per_image[train_images_numbers[index]] = ExtractWordImagesFromOriginalImage(train_jpg_paths[index], train_svg_paths[index])\n",
    "print(train_words_per_image)\n",
    "\n",
    "test_words_per_image = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "# TODO: read from file (the TODO is in the transcription_reader.py file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A-l-e-x-a-n-d-r-i-a', 'C-a-p-t-a-i-n', 'C-l-o-t-h-e-s', 'C-l-o-t-h-i-n-g', 'C-o-l-o-n-e-l', 'C-o-m-m-i-s_s-s-a-r-y', 'C-o-u-r-t', 'C-u-m-b-e-r-l-a-n-d', 'D-i-c-k', 'D-o-c-t-o-r', 'E-n-s-i-g-n', 'F-o-r-t', 'F-o-r-t-s_pt', 'F-r-e-d-e-r-i-c-k-s-b-u-r-g-h-s_cm', 'G-e-o-r-g-e', 'G-u-a-r-d', 'I-n-s-t-r-u-c-t-i-o-n-s-s_pt', 'J-o-h-n', 'L-e-t-t-e-r-s', 'L-i-e-u-t-e-n-a-n-t', 'M-a-j-o-r', 'M-r-s_pt', 'O-f-f-i-c-e-r-s', 'O-r-d-e-r', 'O-r-d-e-r-s', 'O-r-d-e-r-s-s_pt', 'P-a-r-o-l-e', 'R-e-c-r-u-i-t-s', 'R-e-g-i-m-e-n-t', 'R-e-g-i-m-e-n-t-s_pt', 'R-e-n-d-e-z-v-o-u-s', 'R-e-t-u-r-n', 'R-o-b-e-r-t', 'S-a-l-t', 'S-e-r-g-e-a-n-t', 'S-e-r-g-e-a-n-t-s_cm', 'S-h-i-r-t-s-s_cm', 'S-o-l-d-i-e-r-s', 'S-t-e-w-a-r-t-s_cm', 'S-t-o-r-e-s', 'S-u-i-t-s', 'V-i-r-g-i-n-i-a', 'W-a-g-g-o-n-s', 'W-a-s-h-i-n-g-t-o-n-s_cm', 'W-i-n-c-h-e-s-t-e-r', 'W-i-n-c-h-e-s-t-e-r-s_cm', 'W-i-n-c-h-e-s-t-e-r-s_qo', 'a-b-s-o-l-u-t-e-l-y', 'a-r-r-i-v-e', 'a-r-r-i-v-e-s_cm', 'a-t-e-l-y', 'c-a-m-p-s_pt', 'c-a-r-e', 'c-a-r-e-f-u-l', 'c-a-r-r-y', 'd-a-y', 'd-e', 'd-e-l-i-v-e-r', 'd-e-l-i-v-e-r-e-d', 'd-e-s-e-r-t', 'd-i-r-e-c-t-i-o-n-s', 'd-i-s-p-a-t-c-h', 'e-n-g-a-g-e-d', 'e-n-l-i-s-t-e-d', 'e-n-t-e-r', 'e-s-c-o-r-t', 'f-u-r-n-i-s-h', 'g-r-e-a-t-l-y', 'h-u-n-d-r-e-d', 'i-m-m-e-d-i-a-t-e-l-y', 'j-o-i-n', 'l-e-f-t', 'm-a-d-e', 'm-a-k-e', 'm-a-r-c-h', 'm-a-r-c-h-s_cm', 'm-e-d-i-a-t-e-l-y', 'm-e-n', 'm-e-n-s_cm', 'n-u-m-b-e-r', 'o-p-p-o-r-t-u-n-i-t-y', 'o-r-d-e-r', 'o-r-d-e-r-e-d', 'p-a-y', 'p-l-a-c-e', 'p-o-u-n-d-s', 'p-r-o-v-i-d-e', 'p-r-o-v-i-s-i-o-n-s-s_cm', 'p-u-r-c-h-a-s-e', 'q-u-a-n-t-i-t-y', 'r-e-c-e-i-p-t', 'r-e-c-e-i-v-e', 'r-e-c-e-i-v-e-d', 'r-e-m-a-i-n', 'r-e-p-a-i-r', 's-e-n-d', 's_GW', 's_et-c-s_pt', 't-e-r-m-s', 't-h-i-n-g-s', 't-w-e-l-v-e', 'u-n-f-i-t', 'u-t-m-o-s-t', 'w-a-g-g-o-n-s', 'w-a-g-g-o-n-s-s_cm', 'w-a-n-t-e-d', 'w-a-n-t-i-n-g']\n"
     ]
    }
   ],
   "source": [
    "# Extract keywords.\n",
    "keywords = []\n",
    "\n",
    "keywords_path = os.path.join(config.DATA_ROOT_DIR, 'task/keywords.txt')\n",
    "with open(keywords_path) as keywords_file:\n",
    "  for line in keywords_file.readlines():\n",
    "    keywords.append(line.strip())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
