{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import exercise3_config as config\n",
    "from readers import ExtractImagePaths, ExtractTranscriptionsAsDictionary, ExtractTranscriptionsAsList, ExtractKeywords\n",
    "\n",
    "\n",
    "transcriptions_as_dict = ExtractTranscriptionsAsDictionary()\n",
    "transcriptions_as_list = ExtractTranscriptionsAsList()\n",
    "keywords_to_search = ExtractKeywords()\n",
    "\n",
    "# Extract paths for train and test files\n",
    "train_images_numbers, train_jpg_paths, train_svg_paths = \\\n",
    "  ExtractImagePaths(os.path.join(config.DATA_ROOT_DIR, 'task/train.txt'))\n",
    "test_images_numbers, test_jpg_paths, test_svg_paths = \\\n",
    "  ExtractImagePaths(os.path.join(config.DATA_ROOT_DIR, 'task/valid.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from image_preprocessing import CropAllWordImages\n",
    "\n",
    "\n",
    "# TODO: remove this, apply OTSU. This method is here now just for the sake of testing the whole pipeline.\n",
    "# Applies KMeans clustering with the given k on the image at the given path \n",
    "# and returns the output as a a PIL.Image.\n",
    "def ApplyKMeansClusteringToImageFile(jpg_image_filename, k=2):\n",
    "  original_image = cv.imread(jpg_image_filename)\n",
    "  pixels = original_image.reshape((-1,3))\n",
    "  pixels = np.float32(pixels)\n",
    "\n",
    "  # Define criteria, number of clusters and apply KMeans.\n",
    "  criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "  _, label, center = cv.kmeans(pixels, k, None, criteria, 10, cv.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "  # Convert back into uint8.\n",
    "  center = np.uint8(center)\n",
    "  final_image_pixels = center[label.flatten()]\n",
    "  final_image_pixels = final_image_pixels.reshape((original_image.shape))\n",
    "\n",
    "  return Image.fromarray(final_image_pixels)\n",
    "\n",
    "\n",
    "# Applies binarization on the original image, then crops the words using the given mask.\n",
    "def ExtractWordImagesFromOriginalImage(original_image_path, mask_path):\n",
    "  image_after_binarization = ApplyKMeansClusteringToImageFile(original_image_path)\n",
    "  return CropAllWordImages(image_after_binarization, mask_path)\n",
    "\n",
    "\n",
    "# Extracts all words needed for train and test\n",
    "# Output:\n",
    "#  - train_words_per_image: dict containing all train words\n",
    "#  - testt_words_per_image: dict containing all test words\n",
    "# Entries in the output dictionaries are like dict[page_number] = list_of_words\n",
    "def ExtractTrainAndTestWords(train_images_numbers, train_jpg_paths, train_svg_paths,\n",
    "                             test_images_numbers, test_jpg_paths, test_svg_paths):\n",
    "  train_words_per_image = {}\n",
    "  # for index in range(len(train_images_numbers)):\n",
    "  # TODO: iterate over all images. we can leave it like this for now for testing\n",
    "  for index in range(1):\n",
    "    train_words_per_image[train_images_numbers[index]] = ExtractWordImagesFromOriginalImage(train_jpg_paths[index], train_svg_paths[index])\n",
    "\n",
    "  test_words_per_image = {}\n",
    "  # for index in range(len(test_images_numbers)):\n",
    "  # TODO: iterate over all images. we can leave it like this for now for testing\n",
    "  for index in range(1):\n",
    "    test_words_per_image[test_images_numbers[index]] = ExtractWordImagesFromOriginalImage(test_jpg_paths[index], test_svg_paths[index])\n",
    "\n",
    "  return train_words_per_image, test_words_per_image\n",
    "\n",
    "train_words_per_image, test_words_per_image = \\\n",
    "  ExtractTrainAndTestWords(train_images_numbers, train_jpg_paths, train_svg_paths,\n",
    "                           test_images_numbers, test_jpg_paths, test_svg_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word import Word\n",
    "\n",
    "\n",
    "# The following code is not nice but it works because transcriptions and train_words_per_image\n",
    "# are in the same order.\n",
    "train_words = []\n",
    "index = 0\n",
    "for _, train_words_per_current_image in train_words_per_image.items():\n",
    "  for train_word in train_words_per_current_image:\n",
    "    word = Word()\n",
    "    word.image = train_word\n",
    "    word.id = transcriptions_as_list[index][0]\n",
    "    word.transcription = transcriptions_as_list[index][1]\n",
    "    index += 1\n",
    "    train_words.append(word)\n",
    "    # TODO: set features for each Word object\n",
    "\n",
    "\n",
    "test_words = []\n",
    "for image_number, test_words_per_current_image in test_words_per_image.items():\n",
    "  # TODO: remove once we use all files\n",
    "  while transcriptions_as_list[index][0].split(\"-\")[0] != image_number:\n",
    "    index += 1\n",
    "  for test_word in test_words_per_current_image:\n",
    "    word = Word()\n",
    "    word.image = test_word\n",
    "    word.id = transcriptions_as_list[index][0]\n",
    "    word.transcription = transcriptions_as_list[index][1]\n",
    "    index += 1\n",
    "    test_words.append(word)\n",
    "    # TODO: set features for each Word object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Compute distances between all train and test words.\n",
    "# Output:\n",
    "#  - distances: matrix stored as dict of size n x m, where n = len(train_words) \n",
    "#    and m = len(test_words)\n",
    "def ComputeDistances(train_words, test_words):\n",
    "  distances = {}\n",
    "  for train_word in train_words:\n",
    "    distances_from_train_word = {}\n",
    "    for test_word in test_words:\n",
    "      # TODO: Compute real distances\n",
    "      distances_from_train_word[test_word.id] = 0\n",
    "    distances[train_word.id] = distances_from_train_word\n",
    "  return distances\n",
    "\n",
    "\n",
    "distances = ComputeDistances(train_words, test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keyword_spotting import SpotKeyword\n",
    "\n",
    "\n",
    "# Testing\n",
    "SpotKeyword(\"a-n-d\", train_words, test_words, distances)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
