{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import exercise3_config as config\n",
    "from readers import ExtractImagePaths, ExtractTranscriptionsAsList, ExtractKeywords\n",
    "\n",
    "\n",
    "transcriptions_as_list = ExtractTranscriptionsAsList()\n",
    "keywords_to_search = ExtractKeywords()\n",
    "\n",
    "# Extract paths for train and test files\n",
    "train_images_numbers, train_jpg_paths, train_svg_paths = \\\n",
    "  ExtractImagePaths(os.path.join(config.DATA_ROOT_DIR, 'task/train.txt'))\n",
    "test_images_numbers, test_jpg_paths, test_svg_paths = \\\n",
    "  ExtractImagePaths(os.path.join(config.DATA_ROOT_DIR, 'task/valid.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from image_preprocessing import CropAllWordImages\n",
    "\n",
    "\n",
    "# TODO: remove this, apply OTSU. This method is here now just for the sake of testing the whole pipeline.\n",
    "# Applies KMeans clustering with the given k on the image at the given path \n",
    "# and returns the output as a a PIL.Image.\n",
    "def ApplyKMeansClusteringToImageFile(jpg_image_filename, k=2):\n",
    "  original_image = cv.imread(jpg_image_filename)\n",
    "  pixels = original_image.reshape((-1,3))\n",
    "  pixels = np.float32(pixels)\n",
    "\n",
    "  # Define criteria, number of clusters and apply KMeans.\n",
    "  criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "  _, label, center = cv.kmeans(pixels, k, None, criteria, 10, cv.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "  # Convert back into uint8.\n",
    "  center = np.uint8(center)\n",
    "  final_image_pixels = center[label.flatten()]\n",
    "  final_image_pixels = final_image_pixels.reshape((original_image.shape))\n",
    "\n",
    "  return Image.fromarray(final_image_pixels)\n",
    "\n",
    "\n",
    "# Applies binarization on the original image, then crops the words using the given mask.\n",
    "def ExtractWordImagesFromOriginalImage(original_image_path, mask_path):\n",
    "  image_after_binarization = ApplyKMeansClusteringToImageFile(original_image_path)\n",
    "  return CropAllWordImages(image_after_binarization, mask_path)\n",
    "\n",
    "\n",
    "# Extracts all words needed for train and test\n",
    "# Output:\n",
    "#  - train_words_per_image: dict containing all train words\n",
    "#  - testt_words_per_image: dict containing all test words\n",
    "# Entries in the output dictionaries are like dict[page_number] = list_of_words\n",
    "def ExtractTrainAndTestWords(train_images_numbers, train_jpg_paths, train_svg_paths,\n",
    "                             test_images_numbers, test_jpg_paths, test_svg_paths):\n",
    "  train_words_per_image = {}\n",
    "  # for index in range(len(train_images_numbers)):\n",
    "  # TODO: iterate over all images. we can leave it like this for now for testing\n",
    "  for index in range(1):\n",
    "    train_words_per_image[train_images_numbers[index]] = ExtractWordImagesFromOriginalImage(train_jpg_paths[index], train_svg_paths[index])\n",
    "\n",
    "  test_words_per_image = {}\n",
    "  # for index in range(len(test_images_numbers)):\n",
    "  # TODO: iterate over all images. we can leave it like this for now for testing\n",
    "  for index in range(1):\n",
    "    test_words_per_image[test_images_numbers[index]] = ExtractWordImagesFromOriginalImage(test_jpg_paths[index], test_svg_paths[index])\n",
    "\n",
    "  return train_words_per_image, test_words_per_image\n",
    "\n",
    "train_words_per_image, test_words_per_image = \\\n",
    "  ExtractTrainAndTestWords(train_images_numbers, train_jpg_paths, train_svg_paths,\n",
    "                           test_images_numbers, test_jpg_paths, test_svg_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction import Method\n",
    "from word_builder import BuildTrainAndTestWords\n",
    "\n",
    "\n",
    "feature_extraction_methods = [Method.BLACK_PIXEL_RATIO]\n",
    "train_words, test_words = BuildTrainAndTestWords(train_words_per_image, test_words_per_image, transcriptions_as_list, feature_extraction_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: For testing only. Remove the entire cell later\n",
    "\n",
    "# all_train_words = train_words\n",
    "# all_test_words = test_words\n",
    "\n",
    "train_words = train_words[:7]\n",
    "test_words = test_words[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dtaidistance import dtw\n",
    "from compute_distances import ComputeDistances\n",
    "\n",
    "\n",
    "distances = ComputeDistances(train_words, test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keyword_spotting import FindClosestKnownWord\n",
    "\n",
    "\n",
    "# For each test_word, find the train_word that is closest to it.\n",
    "for test_word in test_words:\n",
    "  test_word.closest_train_word, test_word.distance_to_closest_train_word = \\\n",
    "    FindClosestKnownWord(test_word, train_words, distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keyword_spotting import SpotKeyword\n",
    "\n",
    "\n",
    "# Search keywords.\n",
    "for keyword_to_search in keywords_to_search:\n",
    "  spotted_test_keywords = SpotKeyword(keyword_to_search, test_words)\n",
    "  if len(spotted_test_keywords):\n",
    "    print(keyword_to_search)\n",
    "    print(spotted_test_keywords)\n",
    "    for keyword in spotted_test_keywords:\n",
    "      print(keyword.distance_to_closest_train_word)\n",
    "      keyword.image.show()\n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write output file kws.csv (slide 24)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
